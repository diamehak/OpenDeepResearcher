# ğŸš€ OpenDeepResearcher

OpenDeepResearcher is an AI-powered multi-agent research assistant that autonomously plans, searches, analyzes, and synthesizes information into structured reports. The system uses locally hosted large language models via LM Studio, enabling private, cost-efficient, and intelligent deep research workflows without relying on cloud LLM APIs.

---

## âœ¨ Features

- ğŸ” Autonomous research planning with subquestion generation
- ğŸŒ Real-time web search using Tavily API
- ğŸ§  Multi-agent reasoning pipeline (Planner â†’ Searcher â†’ Writer)
- ğŸ“ Academic-style report generation with citations
- ğŸ”’ Local LLM inference using LM Studio (privacy-friendly)
- ğŸ“Š Structured JSON research plans
- âš¡ Modular and extensible architecture

---

## ğŸ—ï¸ System Architecture

The system follows an agent-based pipeline:

1. **Planner Agent**
   - Breaks user queries into 6â€“8 focused subquestions
   - Generates structured research plans
   - Extracts constraints and keywords

2. **Searcher Agent**
   - Retrieves relevant sources using Tavily API
   - Collects titles, URLs, snippets, and relevance scores

3. **Writer Agent**
   - Synthesizes findings into a comprehensive academic report
   - Adds citations and references
   - Saves final output to file

---

## ğŸ¤– Model & Runtime

**LLM Runtime:** LM Studio  
**Model:** Qwen 2.5 7B Instruct  
**Inference:** Local (offline capable)

Benefits:

- No cloud dependency
- Improved privacy
- Lower cost
- Full control over model execution

---

## ğŸ“‚ Project Structure

```
OpenDeepResearcher/
â”‚â”€â”€ agents/
â”‚     â”œâ”€â”€ planner_agent.py
â”‚     â”œâ”€â”€ searcher_agent.py
â”‚     â””â”€â”€ writer_agent.py
â”‚
â”‚â”€â”€ main.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ LICENSE
â”‚â”€â”€ .gitignore
```

---

## âš™ï¸ Installation

Clone the repository:

```bash
git clone https://github.com/diamehak/OpenDeepResearcher.git
cd OpenDeepResearcher
```

Create virtual environment:

```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ§  LM Studio Setup

1. Install **LM Studio**
2. Download **Qwen 2.5 7B Instruct** model
3. Start the LM Studio local server
4. Ensure API endpoint is running:

```
http://127.0.0.1:1234
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the project root:

```
TAVILY_API_KEY=your_api_key_here
```

---

## â–¶ï¸ Usage

Run the main program:

```bash
python main.py
```

Enter your research question when prompted.

Example:

```
Impact of artificial intelligence on healthcare diagnostics
```

The system will:

1. Generate subquestions
2. Search for sources
3. Produce a structured research report
4. Save output to a file

---

## ğŸ“Š Example Output

The system generates:

- Research plan JSON file
- Detailed terminal logs
- Final academic report (.txt)

---

## ğŸ¯ Use Cases

- Academic research assistance
- Literature reviews
- Market analysis
- Technical research
- Policy research
- Automated report generation

---

## ğŸ”® Future Improvements

- Memory-enabled agents
- Multi-modal document ingestion (PDFs)
- Citation formatting (APA/IEEE)
- Web UI dashboard
- Vector database integration
- Streaming responses

---

## ğŸ› ï¸ Tech Stack

- Python
- LM Studio
- Qwen 2.5 7B
- Tavily Search API
- Requests
- Agentic AI architecture

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the repository
2. Create a feature branch
3. Commit changes
4. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

## ğŸ‘¤ Author

Dia Mehak
AI / ML Developer | Agentic AI Enthusiast  

---

â­ If you find this project useful, please consider giving it a star!
